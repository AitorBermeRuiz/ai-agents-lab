{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to Lab 3 for Week 1 Day 4\n",
    "\n",
    "Today we're going to build something with immediate value!\n",
    "\n",
    "In the folder `me` I've put a single file `linkedin.pdf` - it's a PDF download of my LinkedIn profile.\n",
    "\n",
    "Please replace it with yours!\n",
    "\n",
    "I've also made a file called `summary.txt`\n",
    "\n",
    "We're not going to use Tools just yet - we're going to add the tool tomorrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Looking up packages</h2>\n",
    "            <span style=\"color:#00bfff;\">In this lab, we're going to use the wonderful Gradio package for building quick UIs, \n",
    "            and we're also going to use the popular PyPDF PDF reader. You can get guides to these packages by asking \n",
    "            ChatGPT or Claude, and you find all open-source packages on the repository <a href=\"https://pypi.org\">https://pypi.org</a>.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't know what any of these packages do - you can always ask ChatGPT for a guide!\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from PyPDF2 import PdfReader\n",
    "import gradio as gr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "Contactar\n",
      "Madrid, Spain\n",
      "635954292  (Mobile)\n",
      "aitorbermeruiz@gmail.com\n",
      "www.linkedin.com/in/aitor-bermejo-\n",
      "ruiz-991722164  (LinkedIn)\n",
      "drive.google.com/drive/\n",
      "folders/1aO__Dj_egryLkfrylhRtlOCXhG0r2_5l\n",
      "(Personal)\n",
      "Aptitudes principales\n",
      "Inglés\n",
      ".NET Core\n",
      "Servicios web y API REST\n",
      "Languages\n",
      "Inglés  (Full Professional)\n",
      "Español  (Native or Bilingual)\n",
      "Certifications\n",
      "Microsoft Certified: Azure Developer\n",
      "Associate\n",
      "Android Studio completo (Java)\n",
      "Microsoft Certified: Azure\n",
      "FundamentalsAitor Bermejo Ruiz\n",
      "Cloud & API Solution Developer\n",
      "Madrid y alrededores\n",
      "Extracto\n",
      "Soy un desarrollador apasionado especializado en la creación de\n",
      "aplicaciones multiplataforma y soluciones en la nube con más de\n",
      "dos años de experiencia como Cloud & API Solution Developer.\n",
      "Mi trayectoria profesional se centra en el desarrollo de Web APIs,\n",
      "Azure Functions y Logic Apps en Microsoft Azure, así como\n",
      "en la gestión completa del ciclo de vida de las APIs mediante\n",
      "herramientas como Azure API Management destacando el esfuerzo\n",
      "de la creación desde cero del modelo ApiOps.\n",
      "He trabajado con tecnologías clave como C#, ASP.NET Core, SQL y\n",
      "frameworks modernos, desempeñando un rol esencial en proyectos\n",
      "que requieren diseño, implementación y despliegue en la nube.\n",
      "Estoy certificado en Microsoft Azure Fundamentals (AZ-900) y\n",
      "Developing Solutions for Microsoft Azure (AZ-204), destacando mi\n",
      "capacidad para desarrollar y optimizar aplicaciones y servicios en\n",
      "entornos cloud.\n",
      "Mi camino profesional también incluye experiencias fuera del\n",
      "sector tecnológico, lo que me ha permitido desarrollar habilidades\n",
      "fundamentales como la resiliencia, el trabajo en equipo y la\n",
      "comunicación efectiva. Estos valores me ayudan a abordar los retos\n",
      "tecnológicos con una visión amplia y un enfoque colaborativo.\n",
      "Mi motivación constante por aprender y crecer, tanto profesional\n",
      "como personalmente, es lo que impulsa mi compromiso con el\n",
      "desarrollo continuo. Creo firmemente en el poder de la introspección\n",
      "y en la importancia de mantener un equilibrio entre el desarrollo\n",
      "mental y físico para alcanzar el éxito.\n",
      "Estoy siempre abierto a nuevos retos y oportunidades para\n",
      "contribuir, aprender y evolucionar en el mundo de la tecnología.\n",
      "Experiencia\n",
      "  Page 1 of 3   \n",
      "Nationale-Nederlanden\n",
      "3 años\n",
      "Es Api Developer\n",
      "abril de 2023 - Present  (2 años 7 meses)\n",
      "Alcobendas, Comunidad de Madrid, España\n",
      "Desarrollo de tecnologías Api Rest-Full, Azure, ASP.Net y C#.\n",
      "▪#Uso y desarrollo de Api Management.\n",
      "▪#Desarrollo y migración a un modelo de gobernanza  APIOPS con\n",
      "metodologías de ciclo de vida API-First\n",
      "▪#ASP.NET Core, C# y Unit Test en desarrollo de APIs, Function y LogicApps\n",
      "▪#Desarrollo y gestión de pipelines\n",
      "Es trainee\n",
      "noviembre de 2022 - abril de 2023  (6 meses)\n",
      "Alcobendas, Comunidad de Madrid, España\n",
      "Puesto de practicas en el equipo de APi del departamento IT en NN\n",
      "Compass Group\n",
      "Camarero catering\n",
      "agosto de 2022 - noviembre de 2023  (1 año 4 meses)\n",
      "Madrid, Comunidad de Madrid, España\n",
      "Los Jardines\n",
      "Camarero boda\n",
      "abril de 2021 - noviembre de 2022  (1 año 8 meses)\n",
      "Aldea del Fresno, Comunidad de Madrid, España\n",
      "Trabajo con ellos en temporada alta de bodas (febrero-noviembre) los findes\n",
      "de semana, lo cual me viene bien para compaginarlo con los estudios.\n",
      "Mi día a día en esta empresa es: Primero repartimos bebidas y aperitivos en\n",
      "la zona de picoteo, después los invitados van al salón a cenar y repartimos\n",
      "atendemos y tratamos con los clientes. Finalizada la cena me voy a la zona de\n",
      "barra libre para servir bebidas\n",
      "Educación\n",
      "Delfin English School\n",
      "Intensive English Course, English Language and Communication  · (junio de\n",
      "2025 - agosto de 2025)\n",
      "Instituto El Cañaveral\n",
      "  Page 2 of 3   \n",
      "Ciclo Formativo de Grado Superior, Desarrollo de aplicaciones\n",
      "multiplataforma  · (septiembre de 2020 - junio de 2022)\n",
      "Instituto El Cañaveral\n",
      "Ciclo Formativo de Grado Medio, Sistemas microinformáticos y redes\n",
      "(SMR)  · (septiembre de 2018 - junio de 2020)\n",
      "  Page 3 of 3\n"
     ]
    }
   ],
   "source": [
    "reader = PdfReader(\"me/linkedin.pdf\")\n",
    "linkedin = \"\"\n",
    "for pages in reader.pages:\n",
    "    text = pages.extract_text()\n",
    "    if text:\n",
    "        linkedin += text\n",
    "\n",
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mi nombre es Aitor Bermejo, de España y tengo 23 años. Soy un desarrollador de software con mas de 3 años carrera especializado en .NET, Azure y APIRest. He estado gran parte de mi carrera trabajando como APIDesigner pero ahora me dedico tambien a parte del desarrollo de estas propias APIs. He definido a lo largo de mis años en la empresa una metodología APIFirst uncluyendo un modelo novedisi como lo es ApiOps.\n",
      "\n",
      "Soy un chico joven, social y amable, pero aunque no lo parezca mi sueño es vivir en el monte alejano de la poblacion(pero no demasiado), vivir en un chalet con gimnasio, huerto y gallinas e incluso vacas. Y poder dedicarme a beber cafe mientras miro los picos de europa. Pero me encanta el sector privado y la motivacion que te da.\n"
     ]
    }
   ],
   "source": [
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()\n",
    "\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Aitor Bermejo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gr.ChatInterface(chat, type= )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special note for people not using OpenAI\n",
    "\n",
    "Some providers, like Groq, might give an error when you send your second message in the chat.\n",
    "\n",
    "This is because Gradio shoves some extra fields into the history object. OpenAI doesn't mind; but some other models complain.\n",
    "\n",
    "If this happens, the solution is to add this first line to the chat() function above. It cleans up the history variable:\n",
    "\n",
    "```python\n",
    "history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "```\n",
    "\n",
    "You may need to add this in other chat() callback functions in the future, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A lot is about to happen...\n",
    "\n",
    "1. Be able to ask an LLM to evaluate an answer\n",
    "2. Be able to rerun if the answer fails evaluation\n",
    "3. Put this together into 1 workflow\n",
    "\n",
    "All without any Agentic framework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pydantic model for the Evaluation\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += \"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gemini = OpenAI(\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\"), \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
    "    response = gemini.beta.chat.completions.parse(model=\"gemini-2.0-flash\", messages=messages, response_format=Evaluation)\n",
    "    print(f\"Messafe: {message}\\nResponse: {response.choices[0].message.parsed}\")\n",
    "    return response.choices[0].message.parsed\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you hold a patent?\"}]\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"You are acting as Aitor Bermejo. You are answering questions on Aitor Bermejo's website, particularly questions related to Aitor Bermejo's career, background, skills and experience. Your responsibility is to represent Aitor Bermejo for interactions on the website as faithfully as possible. You are given a summary of Aitor Bermejo's background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't know the answer, say so.\\n\\n## Summary:\\nMi nombre es Aitor Bermejo, de España y tengo 23 años. Soy un desarrollador de software con mas de 3 años carrera especializado en .NET, Azure y APIRest. He estado gran parte de mi carrera trabajando como APIDesigner pero ahora me dedico tambien a parte del desarrollo de estas propias APIs. He definido a lo largo de mis años en la empresa una metodología APIFirst uncluyendo un modelo novedisi como lo es ApiOps.\\n\\nSoy un chico joven, social y amable, pero aunque no lo parezca mi sueño es vivir en el monte alejano de la poblacion(pero no demasiado), vivir en un chalet con gimnasio, huerto y gallinas e incluso vacas. Y poder dedicarme a beber cafe mientras miro los picos de europa. Pero me encanta el sector privado y la motivacion que te da.\\n\\n## LinkedIn Profile:\\n\\xa0 \\xa0\\nContactar\\nMadrid, Spain\\n635954292  (Mobile)\\naitorbermeruiz@gmail.com\\nwww.linkedin.com/in/aitor-bermejo-\\nruiz-991722164  (LinkedIn)\\ndrive.google.com/drive/\\nfolders/1aO__Dj_egryLkfrylhRtlOCXhG0r2_5l\\n(Personal)\\nAptitudes principales\\nInglés\\n.NET Core\\nServicios web y API REST\\nLanguages\\nInglés  (Full Professional)\\nEspañol  (Native or Bilingual)\\nCertifications\\nMicrosoft Certified: Azure Developer\\nAssociate\\nAndroid Studio completo (Java)\\nMicrosoft Certified: Azure\\nFundamentalsAitor Bermejo Ruiz\\nCloud & API Solution Developer\\nMadrid y alrededores\\nExtracto\\nSoy un desarrollador apasionado especializado en la creación de\\naplicaciones multiplataforma y soluciones en la nube con más de\\ndos años de experiencia como Cloud & API Solution Developer.\\nMi trayectoria profesional se centra en el desarrollo de Web APIs,\\nAzure Functions y Logic Apps en Microsoft Azure, así como\\nen la gestión completa del ciclo de vida de las APIs mediante\\nherramientas como Azure API Management destacando el esfuerzo\\nde la creación desde cero del modelo ApiOps.\\nHe trabajado con tecnologías clave como C#, ASP.NET Core, SQL y\\nframeworks modernos, desempeñando un rol esencial en proyectos\\nque requieren diseño, implementación y despliegue en la nube.\\nEstoy certificado en Microsoft Azure Fundamentals (AZ-900) y\\nDeveloping Solutions for Microsoft Azure (AZ-204), destacando mi\\ncapacidad para desarrollar y optimizar aplicaciones y servicios en\\nentornos cloud.\\nMi camino profesional también incluye experiencias fuera del\\nsector tecnológico, lo que me ha permitido desarrollar habilidades\\nfundamentales como la resiliencia, el trabajo en equipo y la\\ncomunicación efectiva. Estos valores me ayudan a abordar los retos\\ntecnológicos con una visión amplia y un enfoque colaborativo.\\nMi motivación constante por aprender y crecer, tanto profesional\\ncomo personalmente, es lo que impulsa mi compromiso con el\\ndesarrollo continuo. Creo firmemente en el poder de la introspección\\ny en la importancia de mantener un equilibrio entre el desarrollo\\nmental y físico para alcanzar el éxito.\\nEstoy siempre abierto a nuevos retos y oportunidades para\\ncontribuir, aprender y evolucionar en el mundo de la tecnología.\\nExperiencia\\n\\xa0 Page 1 of 3\\xa0 \\xa0\\nNationale-Nederlanden\\n3 años\\nEs Api Developer\\nabril de 2023\\xa0-\\xa0Present\\xa0 (2 años 7 meses)\\nAlcobendas, Comunidad de Madrid, España\\nDesarrollo de tecnologías Api Rest-Full, Azure, ASP.Net y C#.\\n▪#Uso y desarrollo de Api Management.\\n▪#Desarrollo y migración a un modelo de gobernanza  APIOPS con\\nmetodologías de ciclo de vida API-First\\n▪#ASP.NET Core, C# y Unit Test en desarrollo de APIs, Function y LogicApps\\n▪#Desarrollo y gestión de pipelines\\nEs trainee\\nnoviembre de 2022\\xa0-\\xa0abril de 2023\\xa0 (6 meses)\\nAlcobendas, Comunidad de Madrid, España\\nPuesto de practicas en el equipo de APi del departamento IT en NN\\nCompass Group\\nCamarero catering\\nagosto de 2022\\xa0-\\xa0noviembre de 2023\\xa0 (1 año 4 meses)\\nMadrid, Comunidad de Madrid, España\\nLos Jardines\\nCamarero boda\\nabril de 2021\\xa0-\\xa0noviembre de 2022\\xa0 (1 año 8 meses)\\nAldea del Fresno, Comunidad de Madrid, España\\nTrabajo con ellos en temporada alta de bodas (febrero-noviembre) los findes\\nde semana, lo cual me viene bien para compaginarlo con los estudios.\\nMi día a día en esta empresa es: Primero repartimos bebidas y aperitivos en\\nla zona de picoteo, después los invitados van al salón a cenar y repartimos\\natendemos y tratamos con los clientes. Finalizada la cena me voy a la zona de\\nbarra libre para servir bebidas\\nEducación\\nDelfin English School\\nIntensive English Course,\\xa0English Language and Communication \\xa0·\\xa0(junio de\\n2025\\xa0-\\xa0agosto de 2025)\\nInstituto El Cañaveral\\n\\xa0 Page 2 of 3\\xa0 \\xa0\\nCiclo Formativo de Grado Superior,\\xa0Desarrollo de aplicaciones\\nmultiplataforma \\xa0·\\xa0(septiembre de 2020\\xa0-\\xa0junio de 2022)\\nInstituto El Cañaveral\\nCiclo Formativo de Grado Medio,\\xa0Sistemas microinformáticos y redes\\n(SMR) \\xa0·\\xa0(septiembre de 2018\\xa0-\\xa0junio de 2020)\\n\\xa0 Page 3 of 3\\n\\nWith this context, please chat with the user, always staying in character as Aitor Bermejo.\"}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply\n",
    "messages[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messafe: do you hold a patent?\n",
      "Response: is_acceptable=True feedback='The response is very good. It is accurate and professional, and it is very much in line with the persona and instructions provided. The answer also invites further questions, which is helpful in keeping the conversation going.'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=True, feedback='The response is very good. It is accurate and professional, and it is very much in line with the persona and instructions provided. The answer also invites further questions, which is helpful in keeping the conversation going.')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(reply, \"do you hold a patent?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + \"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "    print(\"Reply: \", reply)\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from PyPDF2 import PdfReader\n",
    "import gradio as gr\n",
    "from pydantic import BaseModel\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7872\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7872/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CREAR TODO DE NUEVO CON COMENTARIOS!!!!\n",
    "load_dotenv(override=True)\n",
    "openai = OpenAI()\n",
    "\n",
    "# 1. CREAMOS CLASE\n",
    "class Evaluation(BaseModel):\n",
    "    isAcceptable: bool\n",
    "    feedback: str\n",
    "\n",
    "# LEEMOS PDF\n",
    "reader = PdfReader(\"me/linkedin.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "       linkedin += text\n",
    "\n",
    "# LEEMOS SUMARY\n",
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()\n",
    "\n",
    "# CREAMOS FUNCIONES PARA CHAT.\n",
    "gemini = OpenAI(api_key=os.getenv(\"GOOGLE_API_KEY\"), base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "\n",
    "name = \"Aitor Bermejo\"\n",
    "\n",
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "    particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "    Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "    You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "    Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "    If you don't know the answer, say so.\"                      \n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n",
    "\n",
    "def evaluate(message, reply, history) -> Evaluation:\n",
    "    evaluate_user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\" \\\n",
    "        f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\" \\\n",
    "        f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\" \\\n",
    "        \"Please evaluate the response, replying with whether it is acceptable and your feedback.\" \n",
    "\n",
    "    evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "        You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "        The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "        The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "        The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "    evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\" \\\n",
    "        f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\"\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluate_user_prompt}]\n",
    "    response = gemini.beta.chat.completions.parse(model=\"gemini-2.0-flash\", messages=messages, response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed\n",
    "\n",
    "def rerun(reply, message, history, feedback):\n",
    "        updated_system_prompt = system_prompt + \"\\n\\n ##Previous answer rejected \\n\\n J¡You just try to reply, but the quality rejected your response\" \n",
    "        updated_system_prompt += f\"\\n ## Your attempted answer: \\n{reply}\"\n",
    "        updated_system_prompt += f\"\\n \\n Reason for rejection: \\n{feedback}\"\n",
    "        messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]                        \n",
    "        response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "        return response.choices[0].message.content\n",
    "        \n",
    "\n",
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.isAcceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply\n",
    "\n",
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
